---
description: Testing patterns and practices
globs: ["**/test_*.py", "**/*.test.ts", "**/*.test.js", "**/*.spec.ts", "**/*.spec.js", "**/tests/**"]
alwaysApply: false
---

# Testing Rules

## Test Structure

- **AAA Pattern:** Arrange → Act → Assert (one logical assertion per test)
- **Descriptive names:** `test_user_creation_fails_with_invalid_email`
- **One behavior per test:** Don't test multiple scenarios in one test
- **No logic in tests:** No conditionals, loops, or complex setup

## Test Isolation

- Tests must not depend on execution order
- Each test sets up and tears down its own state
- No shared mutable state between tests
- Use fixtures/factories for common setup

## What to Test

- **Unit tests:** Pure functions, business logic, edge cases
- **Integration tests:** Database, external APIs, file I/O
- **Boundaries:** Validate at system edges, trust internal code

## What NOT to Test

- Framework/library internals (trust them)
- Private methods directly (test via public interface)
- Trivial getters/setters
- Third-party code behavior

## Mocking Guidelines

- Mock external dependencies (APIs, databases, file system)
- Don't mock the code under test
- Prefer fakes over mocks when possible
- Verify behavior, not implementation details

## Coverage

- Aim for meaningful coverage, not 100%
- Critical paths: 90%+ coverage
- Edge cases and error handling: always tested
- Generated/boilerplate code: exclude from coverage

## Test Failures

- Failing test = stop and fix before proceeding
- Never delete failing tests without fixing the underlying issue
- Tests should fail fast with clear error messages

## Test-First Workflow

- **Test immediately after each change** — don't write multiple files before testing
- **Verify functionality works** before moving to next task
- **Fix issues before proceeding** — never leave broken code behind
- **Run relevant tests** after each modification, not just at the end

## Nodestradamus Test Patterns

### Test File Organization

| Category | Files | Purpose |
|----------|-------|---------|
| Analyzer tests | `test_analyze_*.py` | Language-specific analysis |
| MCP tests | `test_mcp_server.py` | Tool integration tests |
| Dependency tests | `test_*_deps.py` | Language dependency parsing |
| Algorithm tests | `test_graph_algorithms.py` | Graph algorithm correctness |
| Performance tests | `test_performance_*.py` | Timing and caching |

### Fixtures Directory

Test fixtures live in `tests/fixtures/`:

```
tests/fixtures/
├── sample_python/     # Python test files
├── sample_rust/       # Rust test files
├── sample_typescript/ # TS/JS test files
├── sample_sql/        # SQL schema files
├── sample_bash/       # Shell script files
├── sample_schemas/    # Mixed schema examples
├── sample_rules/      # Cursor rule examples
└── synthetic_repo/    # Multi-language test repo
```

### Shared Fixtures

Use `conftest.py` for shared fixtures:

```python
@pytest.fixture
def sample_python_dir(tmp_path):
    """Create a temporary Python project."""
    ...

@pytest.fixture
def mock_graph():
    """Create a test dependency graph."""
    ...
```

### Running Tests

```bash
python -m pytest                          # All tests
python -m pytest tests/test_mcp_server.py # Specific file
python -m pytest -k "analyze_deps"        # By name pattern
python -m pytest -x                       # Stop on first failure
python -m pytest --tb=short               # Shorter tracebacks
```
